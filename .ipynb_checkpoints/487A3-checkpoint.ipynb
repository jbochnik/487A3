{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PA3\") \\\n",
    "    .config(\"spark.some.config.option\",\"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test =  pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df)\n",
    "df_test = spark.createDataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =df.withColumn('plot',lower(regexp_replace(df['plot'],\"[^a-zA-Z ]\",\"\")))\n",
    "df1_test =df_test.withColumn('plot',lower(regexp_replace(df_test['plot'],\"[^a-zA-Z ]\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/cse587/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=23890098, movie_name='Taxi Blues', plot='shlykov a hardworking taxi driver and lyosha a saxophonist develop a bizarre lovehate relationship and despite their prejudices realize they arent so different after all', genre=\"['World cinema', 'Drama']\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "df1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "df1.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()\n",
    "df1_test = df1_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.select('plot')\n",
    "df2_test = df1_test.select('plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rd = df2.rdd.flatMap(list)\n",
    "rd_test = df2_test.rdd.flatMap(list)\n",
    "data = df2.rdd.map(list)\n",
    "data_test = df2_test.rdd.map(list)\n",
    "data = data.map(lambda x: x[0].split())\n",
    "data_test = data_test.map(lambda x: x[0].split())\n",
    "def remove_stop_words(x):\n",
    "    to_remove = []\n",
    "    for word in x:\n",
    "        if word not in stop:\n",
    "            continue\n",
    "        else:\n",
    "            to_remove.append(word)\n",
    "    for word in to_remove:\n",
    "        x.remove(word)\n",
    "    return x\n",
    "data = data.map(remove_stop_words)\n",
    "data_test = data_test.map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd1 = rd.flatMap(lambda x: x.split())\n",
    "rd1_test = rd_test.flatMap(lambda x:x.split())\n",
    "rd1 = rd1.filter(lambda x: x not in stop)\n",
    "rd1_test = rd1_test.filter(lambda x: x not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = rd1.map(lambda x: (x,1))\n",
    "m_test = rd1_test.map(lambda x: (x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = m.reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = wordCount.filter(lambda x: x[1] > 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4312"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = common_words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark .mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def remove_uncommon_words(x):\n",
    "    for word in x:\n",
    "        if word in features:\n",
    "            continue\n",
    "        else:\n",
    "            x.remove(word)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= features.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(remove_uncommon_words)\n",
    "data_test = data_test.map(remove_uncommon_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_map = data.flatMap(lambda token: token).distinct() \\\n",
    "    .zipWithIndex().collectAsMap()\n",
    "\n",
    "vocab_map_test = data_test.flatMap(lambda token: token).distinct() \\\n",
    "    .zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_map = sc.broadcast(vocab_map)\n",
    "vocab_size = sc.broadcast(len(vocab_map))\n",
    "tdm = data \\\n",
    "    .map(Counter) \\\n",
    "    .map(lambda counts: {v_map.value[token]: float(counts[token]) for token in counts})\\\n",
    "    .map(lambda index_counts: SparseVector(vocab_size.value, index_counts))\n",
    "\n",
    "\n",
    "v_map_test = sc.broadcast(vocab_map_test)\n",
    "vocab_size_test = sc.broadcast(len(vocab_map_test))\n",
    "tdm_test = data_test \\\n",
    "    .map(Counter) \\\n",
    "    .map(lambda counts: {v_map_test.value[token]: float(counts[token]) for token in counts})\\\n",
    "    .map(lambda index_counts: SparseVector(vocab_size_test.value, index_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df1.select('genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= labels.rdd.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseVectorsList = tdm.collect()\n",
    "sparseVectorsList_Test = tdm_test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = df.select('movie_id')\n",
    "movie_ids = movie_ids.rdd\n",
    "movie_ids = movie_ids.flatMap(lambda x:x)\n",
    "movie_ids = movie_ids.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keylist = pd.read_csv('mapping.csv')\n",
    "keylist.rename(columns={'Unnamed: 0': 'i'}, inplace=True)\n",
    "keylist = spark.createDataFrame(keylist)\n",
    "k = keylist.select('0')\n",
    "k1 = keylist.select('i')\n",
    "k = k.rdd.flatMap(lambda x:x)\n",
    "k1 = k1.rdd.flatMap(lambda x:x)\n",
    "genre_list = k1.zip(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Drama'),\n",
       " (1, 'Comedy'),\n",
       " (2, 'Romance Film'),\n",
       " (3, 'Thriller'),\n",
       " (4, 'Action'),\n",
       " (5, 'World cinema'),\n",
       " (6, 'Crime Fiction'),\n",
       " (7, 'Horror'),\n",
       " (8, 'Black-and-white'),\n",
       " (9, 'Indie'),\n",
       " (10, 'Action/Adventure'),\n",
       " (11, 'Adventure'),\n",
       " (12, 'Family Film'),\n",
       " (13, 'Short Film'),\n",
       " (14, 'Romantic drama'),\n",
       " (15, 'Animation'),\n",
       " (16, 'Musical'),\n",
       " (17, 'Science Fiction'),\n",
       " (18, 'Mystery'),\n",
       " (19, 'Romantic comedy')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mapFunc(line):\n",
    "#     val = 0.0\n",
    "#     vals = line.map(lambda x: (x[0], x[1]))\n",
    "#     for lab in vals[0]:\n",
    "#         if label == lab:\n",
    "#             val = 1.0\n",
    "#             break\n",
    "#     return LabeledPoint(val, vals[1])\n",
    "\n",
    "def test(data):\n",
    "    ans = []\n",
    "    for i in range(len(data)):\n",
    "        val = 0.0\n",
    "        labels = data[i][0].replace('[','').replace(']','').replace('\\'','').split(',')\n",
    "        for lab in labels:\n",
    "            if lab == label:\n",
    "                val = 1.0\n",
    "                break\n",
    "        pt = LabeledPoint(val, data[i][1])\n",
    "        ans.append(pt)\n",
    "    return ans\n",
    "\n",
    "def makeClassifier(data):\n",
    "#     lab2Data = data.map(mapFunc)\n",
    "    lst = test(data)\n",
    "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
    "#     l2dl = lab2Data.collect()\n",
    "#     return SVMWithSGD.train(sc.parallelize(l2dl), iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2sparse = labels.zip(tdm)\n",
    "lab2sparse_test = labels.zip(tdm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2sm = lab2sparse.map(lambda x: (x[0],x[1]))\n",
    "data = l2sm.collect()\n",
    "l2sm_test =lab2sparse_test.map(lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = l2sm_test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Drama Classifier\n",
      "Trained Comedy Classifier\n",
      "Trained Romance Film Classifier\n",
      "Trained Thriller Classifier\n",
      "Trained Action Classifier\n",
      "Trained World cinema Classifier\n",
      "Trained Crime Fiction Classifier\n",
      "Trained Horror Classifier\n",
      "Trained Black-and-white Classifier\n",
      "Trained Indie Classifier\n",
      "Trained Action/Adventure Classifier\n",
      "Trained Adventure Classifier\n",
      "Trained Family Film Classifier\n",
      "Trained Short Film Classifier\n",
      "Trained Romantic drama Classifier\n",
      "Trained Animation Classifier\n",
      "Trained Musical Classifier\n",
      "Trained Science Fiction Classifier\n",
      "Trained Mystery Classifier\n",
      "Trained Romantic comedy Classifier\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "\n",
    "for label in k.collect():\n",
    "    print('Trained', label, 'Classifier')\n",
    "    classifiers.append(makeClassifier(data))\n",
    "# classifier = makeClassifier(lab2sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['film',\n",
       "  'based',\n",
       "  'events',\n",
       "  'happened',\n",
       "  'ship',\n",
       "  'well',\n",
       "  'events',\n",
       "  'dealing',\n",
       "  'state',\n",
       "  'nurse',\n",
       "  'katherine',\n",
       "  'kitty',\n",
       "  'american',\n",
       "  'karaolos',\n",
       "  'camp',\n",
       "  'thousands',\n",
       "  'jews',\n",
       "  'survivors',\n",
       "  'held',\n",
       "  'british',\n",
       "  'wont',\n",
       "  'let',\n",
       "  'go',\n",
       "  'anxiously',\n",
       "  'wait',\n",
       "  'day',\n",
       "  'ben',\n",
       "  'hagannah',\n",
       "  'rebel',\n",
       "  'previously',\n",
       "  'captain',\n",
       "  'jewish',\n",
       "  'british',\n",
       "  'army',\n",
       "  'second',\n",
       "  'world',\n",
       "  'war',\n",
       "  'cargo',\n",
       "  'ship',\n",
       "  'jewish',\n",
       "  'inmates',\n",
       "  'camp',\n",
       "  'illegal',\n",
       "  'mandate',\n",
       "  'discovered',\n",
       "  'military',\n",
       "  'authorities',\n",
       "  'british',\n",
       "  'find',\n",
       "  'ship',\n",
       "  'famagusta',\n",
       "  'stage',\n",
       "  'strike',\n",
       "  'doctor',\n",
       "  'dies',\n",
       "  'threatens',\n",
       "  'blow',\n",
       "  'ship',\n",
       "  'refugees',\n",
       "  'british',\n",
       "  'allow',\n",
       "  'safe',\n",
       "  'passage',\n",
       "  'meanwhile',\n",
       "  'kitty',\n",
       "  'grown',\n",
       "  'karen',\n",
       "  'young',\n",
       "  'girl',\n",
       "  'searching',\n",
       "  'father',\n",
       "  'separated',\n",
       "  'war',\n",
       "  'taken',\n",
       "  'cause',\n",
       "  'much',\n",
       "  'kitty',\n",
       "  'take',\n",
       "  'young',\n",
       "  'karen',\n",
       "  'america',\n",
       "  'begin',\n",
       "  'new',\n",
       "  'life',\n",
       "  'time',\n",
       "  'partition',\n",
       "  'jewish',\n",
       "  'states',\n",
       "  'young',\n",
       "  'proclaims',\n",
       "  'desire',\n",
       "  'join',\n",
       "  'radical',\n",
       "  'underground',\n",
       "  'network',\n",
       "  'goes',\n",
       "  'address',\n",
       "  'get',\n",
       "  'caught',\n",
       "  'police',\n",
       "  'trap',\n",
       "  'freed',\n",
       "  'members',\n",
       "  'interviewed',\n",
       "  'ben',\n",
       "  'uncle',\n",
       "  'swearing',\n",
       "  'forces',\n",
       "  'boy',\n",
       "  'confess',\n",
       "  'auschwitz',\n",
       "  'raped',\n",
       "  'nazis',\n",
       "  'due',\n",
       "  'activities',\n",
       "  'disowned',\n",
       "  'father',\n",
       "  'heads',\n",
       "  'jewish',\n",
       "  'agency',\n",
       "  'trying',\n",
       "  'create',\n",
       "  'jewish',\n",
       "  'state',\n",
       "  'political',\n",
       "  'means',\n",
       "  'fears',\n",
       "  'damage',\n",
       "  'efforts',\n",
       "  'especially',\n",
       "  'since',\n",
       "  'british',\n",
       "  'put',\n",
       "  'price',\n",
       "  'head',\n",
       "  'successfully',\n",
       "  'bombs',\n",
       "  'king',\n",
       "  'david',\n",
       "  'hotel',\n",
       "  'act',\n",
       "  'leading',\n",
       "  'fatalities',\n",
       "  'arrested',\n",
       "  'sentenced',\n",
       "  'hang',\n",
       "  'meanwhile',\n",
       "  'karens',\n",
       "  'father',\n",
       "  'found',\n",
       "  'ill',\n",
       "  'hospital',\n",
       "  'recognize',\n",
       "  'karen',\n",
       "  'gone',\n",
       "  'live',\n",
       "  'fictional',\n",
       "  'jewish',\n",
       "  'near',\n",
       "  'mount',\n",
       "  'raised',\n",
       "  'actual',\n",
       "  'named',\n",
       "  'dafna',\n",
       "  'located',\n",
       "  'near',\n",
       "  'present',\n",
       "  'border',\n",
       "  'kitty',\n",
       "  'fallen',\n",
       "  'love',\n",
       "  'uncle',\n",
       "  'imprisonment',\n",
       "  'must',\n",
       "  'plan',\n",
       "  'free',\n",
       "  'prisoners',\n",
       "  'landau',\n",
       "  'managed',\n",
       "  'arresting',\n",
       "  'soldiers',\n",
       "  'turns',\n",
       "  'use',\n",
       "  'knowledge',\n",
       "  'explosives',\n",
       "  'prison',\n",
       "  'plan',\n",
       "  'escape',\n",
       "  'route',\n",
       "  'goes',\n",
       "  'according',\n",
       "  'plan',\n",
       "  'hundreds',\n",
       "  'prisoners',\n",
       "  'including',\n",
       "  'manage',\n",
       "  'escape',\n",
       "  'incident',\n",
       "  'based',\n",
       "  'see',\n",
       "  'acre',\n",
       "  'prison',\n",
       "  'break',\n",
       "  'akiva',\n",
       "  'fatally',\n",
       "  'shot',\n",
       "  'british',\n",
       "  'soldiers',\n",
       "  'roadblock',\n",
       "  'set',\n",
       "  'catch',\n",
       "  'escaped',\n",
       "  'prisoners',\n",
       "  'also',\n",
       "  'badly',\n",
       "  'wounded',\n",
       "  'makes',\n",
       "  'way',\n",
       "  'yesha',\n",
       "  'village',\n",
       "  'near',\n",
       "  'dafna',\n",
       "  'friend',\n",
       "  'mukhtar',\n",
       "  'kitty',\n",
       "  'brought',\n",
       "  'treats',\n",
       "  'wound',\n",
       "  'independent',\n",
       "  'plain',\n",
       "  'view',\n",
       "  'nationals',\n",
       "  'mohammad',\n",
       "  'alhusayni',\n",
       "  'grand',\n",
       "  'jerusalem',\n",
       "  'plot',\n",
       "  'attack',\n",
       "  'dafna',\n",
       "  'kill',\n",
       "  'villagers',\n",
       "  'ari',\n",
       "  'receives',\n",
       "  'prior',\n",
       "  'warning',\n",
       "  'attack',\n",
       "  'manages',\n",
       "  'get',\n",
       "  'younger',\n",
       "  'children',\n",
       "  'town',\n",
       "  'mass',\n",
       "  'escape',\n",
       "  'karen',\n",
       "  'prospect',\n",
       "  'new',\n",
       "  'finds',\n",
       "  'proclaims',\n",
       "  'love',\n",
       "  'assures',\n",
       "  'marry',\n",
       "  'karen',\n",
       "  'returns',\n",
       "  'dafna',\n",
       "  'ambushed',\n",
       "  'killed',\n",
       "  'gang',\n",
       "  'militiamen',\n",
       "  'dov',\n",
       "  'discovers',\n",
       "  'body',\n",
       "  'following',\n",
       "  'morning',\n",
       "  'day',\n",
       "  'body',\n",
       "  'found',\n",
       "  'hanging',\n",
       "  'village',\n",
       "  'killed',\n",
       "  'arab',\n",
       "  'extremists',\n",
       "  'star',\n",
       "  'david',\n",
       "  'carved',\n",
       "  'body',\n",
       "  'karen',\n",
       "  'buried',\n",
       "  'together',\n",
       "  'one',\n",
       "  'grave',\n",
       "  'jewish',\n",
       "  'ceremony',\n",
       "  'ari',\n",
       "  'swears',\n",
       "  'bodies',\n",
       "  'jews',\n",
       "  'live',\n",
       "  'together',\n",
       "  'share',\n",
       "  'land',\n",
       "  'peace',\n",
       "  'death',\n",
       "  'also',\n",
       "  'life',\n",
       "  'movie',\n",
       "  'ends',\n",
       "  'ari',\n",
       "  'kitty',\n",
       "  'contingent',\n",
       "  'entering',\n",
       "  'heading',\n",
       "  'toward',\n",
       "  'battle']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from pyspark.mllib.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
