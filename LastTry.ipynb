{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import re\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder,StringIndexer, VectorAssembler\n",
    "import numpy as np\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.linalg import Vector as MllibVector, Vectors as MLLibVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PA3\") \\\n",
    "    .config(\"spark.some.config.option\",\"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.withColumn('plot',lower(regexp_replace(df['plot'],\"[^a-zA-Z ]\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexToken = RegexTokenizer(inputCol='plot',outputCol='tokens', pattern=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = regexToken.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsRemover = StopWordsRemover(inputCol = 'tokens',outputCol = 'cleaned').setStopWords(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stopWordsRemover.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = CountVectorizer(inputCol= 'cleaned',outputCol= 'features',minDF=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = counts.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " df =df.drop('plot','tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.select('genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= labels.rdd.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = df.select('features')\n",
    "feat = feat.rdd.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = feat.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = df.select('movie_id')\n",
    "movie_ids = movie_ids.rdd\n",
    "movie_ids = movie_ids.flatMap(lambda x:x)\n",
    "movie_ids = movie_ids.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keylist = pd.read_csv('mapping.csv')\n",
    "keylist.rename(columns={'Unnamed: 0': 'i'}, inplace=True)\n",
    "keylist = spark.createDataFrame(keylist)\n",
    "k = keylist.select('0')\n",
    "k1 = keylist.select('i')\n",
    "k = k.rdd.flatMap(lambda x:x)\n",
    "k1 = k1.rdd.flatMap(lambda x:x)\n",
    "genre_list = k1.zip(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data):\n",
    "    ans = []\n",
    "    for i in range(len(data)):\n",
    "        val = 0.0\n",
    "        labels = data[i][0].replace('[','').replace(']','').replace('\\'','').split(',')\n",
    "        for lab in labels:\n",
    "            if lab == label:\n",
    "                val = 1.0\n",
    "                break\n",
    "        pt = LabeledPoint(val, MLLibVectors.sparse(data[i][1].size,data[i][1].indices,data[i][1].values))\n",
    "        ans.append(pt)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeClassifier(data):\n",
    "    lst = test(data)\n",
    "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2sparse = labels.zip(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"['World cinema', 'Drama']\",\n",
       "  SparseVector(24527, {126: 1.0, 180: 1.0, 499: 1.0, 536: 1.0, 576: 1.0, 1867: 1.0, 2074: 1.0, 3127: 1.0, 5254: 1.0, 8209: 1.0, 13154: 1.0, 21390: 1.0, 21912: 1.0}))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab2sparse.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2sm = lab2sparse.map(lambda x: (x[0],x[1]))\n",
    "data = l2sm.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"['World cinema', 'Drama']\",\n",
       " SparseVector(24527, {126: 1.0, 180: 1.0, 499: 1.0, 536: 1.0, 576: 1.0, 1867: 1.0, 2074: 1.0, 3127: 1.0, 5254: 1.0, 8209: 1.0, 13154: 1.0, 21390: 1.0, 21912: 1.0}))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Drama Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 34468)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41677)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-4da37e29aa38>\", line 5, in <module>\n",
      "    classifiers.append(makeClassifier(data))\n",
      "  File \"<ipython-input-22-66aee14af7df>\", line 3, in makeClassifier\n",
      "    return SVMWithSGD.train(sc.parallelize(lst), iterations=100)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 557, in train\n",
      "    return _regression_train_wrapper(train, SVMModel, data, initialWeights)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\", line 220, in _regression_train_wrapper\n",
      "    weights, intercept = train_func(data, _convert_to_vector(initial_weights))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\", line 555, in train\n",
      "    bool(intercept), bool(validateData), float(convergenceTol))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 130, in callMLlibFunc\n",
      "    return callJavaFunc(sc, api, *args)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 123, in callJavaFunc\n",
      "    return _java2py(sc, func(*args))\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o327.trainSVMModelWithSGD\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse587/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o327.trainSVMModelWithSGD",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4da37e29aa38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trained'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmakeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-66aee14af7df>\u001b[0m in \u001b[0;36mmakeClassifier\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmakeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSVMWithSGD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, data, iterations, step, regParam, miniBatchFraction, initialWeights, regType, intercept, validateData, convergenceTol)\u001b[0m\n\u001b[1;32m    555\u001b[0m                                  bool(intercept), bool(validateData), float(convergenceTol))\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_regression_train_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVMModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\u001b[0m in \u001b[0;36m_regression_train_wrapper\u001b[0;34m(train_func, modelClass, data, initial_weights)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodelClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_convert_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodelClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rdd, i)\u001b[0m\n\u001b[1;32m    553\u001b[0m             return callMLlibFunc(\"trainSVMModelWithSGD\", rdd, int(iterations), float(step),\n\u001b[1;32m    554\u001b[0m                                  \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminiBatchFraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                                  bool(intercept), bool(validateData), float(convergenceTol))\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_regression_train_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVMModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o327.trainSVMModelWithSGD"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "\n",
    "for label in k.collect():\n",
    "    print('Trained', label, 'Classifier')\n",
    "    classifiers.append(makeClassifier(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {}\n",
    "for i in range(len(sparseVectorsList_Test)):\n",
    "    res = []\n",
    "    movie_id = movie_ids[i]\n",
    "    sv = sparseVectorsList_Test[i]\n",
    "    for classifier in classifiers:\n",
    "        res.append(classifier.predict(sv))\n",
    "    ans[movie_id] = res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
